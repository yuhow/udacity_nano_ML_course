{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: <br>\n",
    "review link of my proposal: https://review.udacity.com/#!/reviews/1076422"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer Nanodegree\n",
    "\n",
    "## Capstone Project -- TalkingData AdTracking Fraud Detection Challenge\n",
    "<br>\n",
    "<br>\n",
    "Yoh-Hao Chang <br>\n",
    "question0802@gmail.com <br>\n",
    "Mar. 8th, 2018\n",
    "***\n",
    "\n",
    "## I. Definition\n",
    "### Project Overview\n",
    "Fraud risk is everywhere, but for companies that advertise online, click fraud can happen at an overwhelming volume, resulting in misleading click data and wasted money. Ad channels can drive up costs by simply clicking on the ad at a large scale. With over 1 billion smart mobile devices in active use every month, China is the largest mobile market in the world and therefore suffers from huge volumes of fraudulent traffic. In the paper, ‘Detecting Click Fraud in Online Advertising: A Data Mining Approach’ (JMLR, v.15 n.1, p.99-140, Jan. 2014), it summarize lots of observations and analyses of the fraud click detection. It also addressed some important issues in data mining and machine learning research, including highly imbalanced distribution of the output variable, heterogeneous data (mixture of numerical and categorical variables), and noisy patterns with missing or unknown values. \n",
    "\n",
    "TalkingData, China’s largest independent big data service platform, covers over 70% of active mobile devices nationwide. They handle 3 billion clicks per day, of which 90% are potentially fraudulent. Their current approach to prevent click fraud for app developers is to measure the journey of a user’s click across their portfolio, and flag IP addresses who produce lots of clicks, but never end up installing apps. With this information, they’ve built an IP blacklist and device blacklist.\n",
    "\n",
    "A generous dataset covering approximately 200 million clicks over 4 days is provided for this project. All of the necessary data sets can be found and download from: https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/data\n",
    "\n",
    "There are about hundreds million recorded data and each data entry is with 8 features. It contains some features like: IP address of click, App. ID for marketing, operation system (OS) version ID of user mobile phone, device type ID of user mobile phone, the target that is to be predicted, indicating the app was downloaded, etc. Some features of data are encoded already. Except of two features are recorded in UTC time format.\n",
    "\n",
    "### Problem Statement\n",
    "The problem is quite straightforward: **how to know whether a user will really download an app after clicking a mobile app ad? That is, how to distinguish between meaningful clicks and fraud clicks?** Currently, TalkingData does have some methods to prevent click fraud. But there are still rooms for improvement. While successful, they can then always be one step ahead of those fraudsters. So our goal is to **develop an algorithm/model which can precisely predict whether a user will download an app after clicking a mobile app ad based on the recorded properties of that user**. The performance of model will be evaluated on area under the Receiver operating characteristic (ROC) curve between the predicted probability and the observed target. The smaller differences between our predictions and truths, the better our solution model will be. Then such model can be used to distinguish between meaningful clicks and fraud clicks and reduced the amount of wasted money caused by fraudulence.\n",
    "\n",
    "This project is actually taken from one of Kaggle competitions. They provide a benchmark model which is developed by a random forest method. The socre of this benchmark model is 0.911. And the score is exactly evaluated on area under the Receiver operating characteristic (ROC) curve between the predicted probability and the observed target.\n",
    "\n",
    "<img src=\"images/work_flow.jpg\" alt=\"Drawing\" style=\"width: 400px;\"/>\n",
    "\n",
    "By following a very traditional but useful work flow, we first approach this problem by investigating the data. Through this exploratory data analysis, we can establish some basic ideas about the interrelationship between different features or the natural properties of each feature itself. We can even create some new features based on the existing features.\n",
    "\n",
    "Next, we have to check and clean the data. Maybe sometime our data will contain lots of different values or even missing values. So in feature engineering of data for our model developing, we will handle the problem of missing value and outliers, and/or normalize numeric features. If we have any categorical feature or text format feature, additional data preprocessing techniques will be included. For developing a proper model for our project, we now will split the whole training data set into to three pieces: one for training, another for validation and the other for testing. This step is for cross-validation.\n",
    "\n",
    "Basically, two kinds of classifiers will be built in this project: one is based on the neural network; the other is based on the random forest. Grid search method will be optional for finding the best combination of model’s parameters. Once we have finished training the models. They will be evaluated by using the evaluation metric, area under the Receiver operating characteristic curve (AUC). Models will be check thoroughly to see if there is anything insufficient. \n",
    "\n",
    "Kaggle’s official evaluation will be also taken into account. Depending on the performance of these models, we maybe have to go to some previous step to see if there is anything missing or wrong. Once we have an acceptable model (the one with better\n",
    "performance on evaluation and testing), whose score is at least over 0.92, we can stop and publish that model.\n",
    "\n",
    "### Metrics\n",
    "Evaluation metric will be the area under the Receiver operating characteristic (ROC) curve between the predicted probability and the observed target. Such metric is also called as ‘AUC’. AUC as a further interpretation of ROC is a very straightforward and easyunderstanding metric of a binary classifier system. Since now we are trying to establish a model to predict whether a user will download an app after clicking a mobile app or not. This is exactly a binary classification problem. Given a threshold parameter $T$, the instance is classified as “positive” if $X>T$, and “negative” otherwise. $X$ follows a probability density $f_{1}(x)$ if the instance actually belongs to class “positive”, and $f_{0}(x)$ if otherwise. Therefore, the true positive rate is given by $TPR(T)=\\int_{T}^{\\infty}f_{1}(x)dx$ and the false positive rate is given by $FPR(T)=\\int_{T}^{\\infty}f_{0}(x)dx$. \n",
    "\n",
    "The ROC curve plots parametrically $TPR(T)$ versus $FPR(T)$ with $T$ as the varying parameter. Then the AUC is simply the area under the ROC. Generally, we can judge our model through the value of AUC like follows:\n",
    "- AUC=0.5 (no discrimination)\n",
    "- 0.7 ≦ AUC ≦ 0.8 (acceptable discrimination)\n",
    "- 0.8 ≦ AUC ≦ 0.9 (excellent discrimination)\n",
    "- 0.9 ≦ AUC ≦ 1.0 (outstanding discrimination)\n",
    "\n",
    "Ref: https://en.wikipedia.org/wiki/Receiver_operating_characteristic\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Analysis\n",
    "### Data Exploration\n",
    "Input training data can be download from: https://www.kaggle.com/c/talkingdata-adtracking-fraud-detection/data\n",
    "- **train.csv** - the training set\n",
    "- **train_sample.csv** - 100,000 randomly-selected rows of training data, to inspect data before downloading full set\n",
    "\n",
    "The size of the data (train.csv) is really quite big. It maybe takes much time use the whole training data set and the whole testing data set for our model development and self-evaluation due to limited memory. There are 200 million recorded data and each data entry is with 8 features. It contains some features like: IP address of click, App. ID for marketing, operation system (OS) version ID of user mobile phone, device type ID of user mobile phone, the target that is to be predicted, indicating the app was downloaded, etc. Some features of data are encoded already. Except of two features are recorded in UTC time format. There is a data sample (train_sample.csv) provided for quick inspection.\n",
    "\n",
    "Each row of the training data contains a click record, with the following features.\n",
    "- **ip**: ip address of click.\n",
    "- **app**: app id for marketing.\n",
    "- **device**: device type id of user mobile phone (e.g., iphone 6 plus, iphone 7, huawei mate 7, etc.)\n",
    "- **os**: os version id of user mobile phone\n",
    "- **channel**: channel id of mobile ad publisher\n",
    "- **click_time**: timestamp of click (UTC)\n",
    "- **attributed_time**: if user download the app for after clicking an ad, this is the time of the app download \n",
    "\n",
    "Note that ip, app, device, os, and channel are encoded.\n",
    "\n",
    "The test data for Kaggle Leaderboard ranking is similar, with the following differences: <br>\n",
    "- **click_id**: reference for making predictions\n",
    "\n",
    "**Target Variable**\n",
    "- **is_attributed**: the target that is to be predicted, indicating the app was downloaded (not included in the test data for Kaggle Leaderboard ranking)\n",
    "\n",
    "https://github.com/div3125/udacity-mlnd-capstone/blob/master/report.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998307\n",
      "1694\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display # Allows the use of display() for DataFrames\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "#data_sample = pd.read_csv('data/train_sample.csv')\n",
    "#data = pd.read_csv('data/train.csv', chunksize=1000000)\n",
    "#print data_sample.head\n",
    "#print data\n",
    "#for chunk in pd.read_csv('data/train.csv', chunksize = 1000000):\n",
    "fraud = 0\n",
    "not_fraud = 1\n",
    "for chunk in pd.read_csv('data/train_sample.csv', chunksize = 1000000):\n",
    "    fraud += data[data['is_attributed']==0].shape[0]\n",
    "    not_fraud += data[data['is_attributed']==1].shape[0]\n",
    "print fraud\n",
    "print not_fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAETCAYAAAA/NdFSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x53e1ec50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "prob_not_fraud = float(not_fraud)/float(not_fraud+fraud)\n",
    "prob_fraud = float(fraud)/float(not_fraud+fraud)\n",
    "ax = sns.barplot(x=['not fraud(1)', 'fraud(0)'], y=[prob_not_fraud, prob_fraud])\n",
    "ax.set(xlabel='Target Value', ylabel='Probability', title='Target value distribution')\n",
    "for p, uniq in zip(ax.patches, [prob_not_fraud, prob_fraud]):\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+p.get_width()/2.,\n",
    "            height+0.01,\n",
    "            '{}%'.format(round(uniq * 100, 2)),\n",
    "            ha=\"center\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named imblearn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-9e3abba89e0c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mimblearn\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named imblearn"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
